{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae36a476-6422-4973-abbe-7e6261bfd02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf497575-1110-498e-9f59-9288681f823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, ConfusionMatrixDisplay\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552408fa-a8ff-408c-bcdf-cc306d4df7f1",
   "metadata": {},
   "source": [
    "# 1) Load the Iris dataset and create a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a6874dd-eee7-4e83-93c9-eb248c75c581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "  species  \n",
      "0  setosa  \n",
      "1  setosa  \n",
      "2  setosa  \n",
      "3  setosa  \n",
      "4  setosa  \n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "# Feature matrix and target\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "# Create a DataFrame for easier inspection and preprocessing\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "# Map numeric target to species names so we can demonstrate encoding\n",
    "df['species'] = pd.Categorical.from_codes(y, iris.target_names)\n",
    "\n",
    "\n",
    "# Show the first rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d01309-2183-4399-922f-7779b6281e74",
   "metadata": {},
   "source": [
    "# 2) Preprocessing: check and handle missing values, encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda620d9-ba39-4aba-b36e-d995f37d7c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "sepal length (cm)    0\n",
      "sepal width (cm)     0\n",
      "petal length (cm)    0\n",
      "petal width (cm)     0\n",
      "species              0\n",
      "dtype: int64\n",
      "\n",
      "Label classes: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Check for missing values\n",
    "print('\\nMissing values per column:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "# If there were missing values in features, we could impute them. Demonstrate using SimpleImputer.\n",
    "# (Iris dataset has no missing values, but this shows the correct approach.)\n",
    "feature_cols = iris.feature_names\n",
    "imputer = SimpleImputer(strategy='mean') # replace missing numeric values with column mean\n",
    "X_imputed = imputer.fit_transform(df[feature_cols])\n",
    "\n",
    "\n",
    "# 2.2 Encode labels (species -> numeric)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(df['species'])\n",
    "print('\\nLabel classes:', le.classes_)\n",
    "\n",
    "\n",
    "# Prepare final feature matrix and labels\n",
    "X_final = X_imputed\n",
    "y_final = y_encoded = y_encoded = y_encoded = y_encoded = y_encoded if False else y_encoded if False else y_encoded\n",
    "# The above line is intentionally overwritten in the next line to keep the notebook simple.\n",
    "# Use the encoded labels we created via LabelEncoder\n",
    "y_final = le.transform(df['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ae4c01-3269-427a-861c-a5302d92bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7f816d-a6d8-4a39-9349-1c90ae2884c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.2, random_state=42, stratify=y_final)\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634f7882-444d-4fdf-833b-3bd514769fcf",
   "metadata": {},
   "source": [
    "# 4) Train a Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49fe97f-ffb8-4286-a55c-aca1504e72fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e03cde-26a6-41ef-b592-473e09e2eddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Evaluate the model using accuracy, precision, and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d725f2c2-350c-4d7d-96e0-251065a78123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision_macro = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "recall_macro = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "\n",
    "print('\\nEvaluation metrics on test set:')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision (macro): {precision_macro:.4f}')\n",
    "print(f'Recall (macro): {recall_macro:.4f}')\n",
    "\n",
    "\n",
    "print('\\nFull classification report:')\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "\n",
    "# Confusion matrix display\n",
    "disp = ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test, display_labels=le.classes_, cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - Decision Tree (Iris)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb746a1d-b03e-4c3d-9476-a06c1fc0799f",
   "metadata": {},
   "source": [
    "# 6) Visualize the trained decision tree (simple plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9aaa01-d49c-4842-9e2b-9a2f7fb2b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plot_tree(clf, feature_names=feature_cols, class_names=le.classes_, filled=True, rounded=True)\n",
    "plt.title('Decision Tree Structure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc34326-ee40-4222-a275-1251e9141e55",
   "metadata": {},
   "source": [
    "# 7) Save the trained model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3822ad-bcef-4061-948a-3df3f6556bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'iris_decision_tree_joblib.pkl'\n",
    "joblib.dump({'model': clf, 'label_encoder': le, 'imputer': imputer}, model_filename)\n",
    "print(f\"Model and preprocessing objects saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf30d45-65fb-4f7e-89f4-ef85498cde5a",
   "metadata": {},
   "source": [
    "# Example predictions on new samples (showing how to use the saved pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfef837-c381-403e-bfef-b2df69e0780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_samples = X_test[:5] # take first 5 test samples\n",
    "preds = clf.predict(new_samples)\n",
    "pred_names = le.inverse_transform(preds)\n",
    "print('\\nExample predictions on 5 test samples:')\n",
    "for i, (sample, p) in enumerate(zip(new_samples, pred_names)):\n",
    "print(f'Sample {i+1}: features={np.round(sample,2)} --> predicted species = {p}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
